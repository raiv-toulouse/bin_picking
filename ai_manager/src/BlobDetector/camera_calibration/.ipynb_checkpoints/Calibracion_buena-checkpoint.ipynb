{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script we get the camera parameters and we manage to get rid of the distorsion. All of the values are stored, so can be accesible at any time and use them for our aplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix : \n",
      "\n",
      "[[834.00591523   0.         323.37115401]\n",
      " [  0.         834.18405282 233.38065856]\n",
      " [  0.           0.           1.        ]]\n",
      "Dist : \n",
      "\n",
      "[[ 4.83254201e-02 -1.50211706e+00 -3.34880287e-03  3.28212031e-03\n",
      "   1.21495774e+01]]\n",
      "Region of Interest: \n",
      "\n",
      "(14, 12, 613, 455)\n",
      "New Camera Matrix: \n",
      "\n",
      "[[843.97436523   0.         324.11815291]\n",
      " [  0.         834.54827881 232.74909601]\n",
      " [  0.           0.           1.        ]]\n",
      "Inverse New Camera Matrix: \n",
      "\n",
      "[[ 0.00118487  0.         -0.38403791]\n",
      " [ 0.          0.00119825 -0.27889231]\n",
      " [ 0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "# workingdir=\"/home/pi/Desktop/Captures/\"\n",
    "savedir = 'camera_data/'\n",
    "\n",
    "# Defining the dimensions of checkerboard\n",
    "CHECKERBOARD = (6,5)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Creating vector to store vectors of 3D points for each checkerboard image\n",
    "objpoints = []\n",
    "# Creating vector to store vectors of 2D points for each checkerboard image\n",
    "imgpoints = [] \n",
    "\n",
    "\n",
    "# Defining the world coordinates for 3D points\n",
    "objp = np.zeros((1, CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "prev_img_shape = None\n",
    "\n",
    "# Extracting path of individual image stored in a given directory\n",
    "images = glob.glob('./final_pictures/*.png')\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    # If desired number of corners are found in the image then ret = true\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    \n",
    "    \"\"\"\n",
    "    If desired number of corner are detected,\n",
    "    we refine the pixel coordinates and display \n",
    "    them on the images of checker board\n",
    "    \"\"\"\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        # refining pixel coordinates for given 2d points.\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), criteria)\n",
    "        \n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "h,w = img.shape[:2]\n",
    "\n",
    "\"\"\"\n",
    "Performing camera calibration by \n",
    "passing the value of known 3D points (objpoints)\n",
    "and corresponding pixel coordinates of the \n",
    "detected corners (imgpoints)\n",
    "\"\"\"\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Printing  and saving the results\n",
    "print(\"Camera matrix : \\n\")\n",
    "print(mtx)\n",
    "np.save(savedir + 'cam_mtx.npy', mtx)\n",
    "\n",
    "print(\"Dist : \\n\")\n",
    "print(dist)\n",
    "np.save(savedir + 'dist.npy', dist)\n",
    "\n",
    "### UNDISTORSION ####\n",
    "\n",
    "# Refining the camera matrix using parameters obtained by calibration\n",
    "new_camera_mtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "print(\"Region of Interest: \\n\")\n",
    "print(roi)\n",
    "np.save(savedir+'roi.npy', roi)\n",
    "\n",
    "print(\"New Camera Matrix: \\n\")\n",
    "#print(newcam_mtx)\n",
    "np.save(savedir+'newcam_mtx.npy', new_camera_mtx)\n",
    "print(np.load(savedir+'newcam_mtx.npy'))\n",
    "\n",
    "inverse_newcam_mtx = np.linalg.inv(new_camera_mtx)\n",
    "print(\"Inverse New Camera Matrix: \\n\")\n",
    "print(inverse_newcam_mtx)\n",
    "np.save(savedir+'inverse_newcam_mtx.npy', inverse_newcam_mtx)\n",
    "\n",
    "# Method 1 to undistort the image\n",
    "dst = cv2.undistort(img, mtx, dist, None, new_camera_mtx)\n",
    "\n",
    "# Displaying the undistorted image\n",
    "cv2.imshow(\"undistorted image\",dst)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Closing all remaining windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the parameters in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'camera_matrix': np.asarray(mtx).tolist(),\n",
    "        'dist_coeff': np.asarray(dist).tolist(),\n",
    "        'roi': np.asarray(roi).tolist(),\n",
    "        'new_camera_mtx': np.asarray(new_camera_mtx).tolist(),\n",
    "        'inverse_newcam_mtx':np.asarray(inverse_newcam_mtx).tolist()\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the matrix and distortion coefficients to writable lists\n",
    "# and save it to a file\n",
    "with open(\"calibration_matrix.yaml\", \"w\") as f:\n",
    "     yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Perspective Calibration Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# parameters \n",
    "writeValues = True\n",
    "display = False\n",
    "savedir = \"camera_data/\"\n",
    "\n",
    "# Get the center of the image cx and cy\n",
    "def get_image_center(savedir):\n",
    "        \n",
    "    # load camera calibration\n",
    "    newcam_mtx = np.load(savedir+'newcam_mtx.npy')\n",
    "\n",
    "    # load center points from New Camera matrix\n",
    "    cx = newcam_mtx[0,2]\n",
    "    cy = newcam_mtx[1,2]\n",
    "    fx = newcam_mtx[0,0]\n",
    "    return cx,cy\n",
    "\n",
    "# Load parameters from the camera\n",
    "def load_parameters(savedir, display):\n",
    "    # load camera calibration\n",
    "    savedir = \"camera_data/\"\n",
    "    cam_mtx = np.load(savedir+'cam_mtx.npy')\n",
    "    dist = np.load(savedir+'dist.npy')\n",
    "    roi = np.load(savedir+'roi.npy')\n",
    "    newcam_mtx = np.load(savedir+'newcam_mtx.npy')\n",
    "    inverse_newcam_mtx = np.load(savedir+'inverse_newcam_mtx.npy')\n",
    "    \n",
    "    if display:\n",
    "        print (\"Camera Matrix :\\n {0}\".format(cam_mtx))\n",
    "        print (\"Dist Coeffs :\\n {0}\".format(dist))\n",
    "        print(\"Region of Interest :\\n {0}\".format(roi))\n",
    "        print(\"New Camera Matrix :\\n {0}\".format(newcam_mtx))\n",
    "        print(\"Inverse New Camera Matrix :\\n {0}\".format(inverse_newcam_mtx))\n",
    "            \n",
    "    return cam_mtx,dist,roi,newcam_mtx,inverse_newcam_mtx\n",
    "\n",
    "def save_parameters(savedir,rotation_vector, translation_vector,newcam_mtx):\n",
    "    \n",
    "    # Rotation Vector\n",
    "    np.save(savedir + 'rotation_vector.npy', rotation_vector)\n",
    "    np.save(savedir + 'translation_vector.npy', translation_vector)\n",
    "    \n",
    "    # Rodrigues\n",
    "    # print(\"R - rodrigues vecs\")\n",
    "    R_mtx, jac = cv2.Rodrigues(rotation_vector)\n",
    "    np.save(savedir + 'R_mtx.npy', R_mtx)  \n",
    "    \n",
    "    # Extrinsic Matrix\n",
    "    Rt = np.column_stack((R_mtx,translation_vector))\n",
    "    # print(\"R|t - Extrinsic Matrix:\\n {0}\".format(Rt))\n",
    "    np.save(savedir + 'Rt.npy', Rt)\n",
    "    \n",
    "    # Projection Matrix      \n",
    "    P_mtx=newcam_mtx.dot(Rt)\n",
    "    # print(\"newCamMtx*R|t - Projection Matrix:\\n {0}\".format(P_mtx))\n",
    "    np.save(savedir + 'P_mtx.npy', P_mtx)\n",
    "    \n",
    "def load_checking_parameters(savedir):\n",
    "    \n",
    "    rotation_vector = np.load(savedir+'rotation_vector.npy')\n",
    "    translation_vector = np.load(savedir+'translation_vector.npy')\n",
    "    R_mtx = np.load(savedir+'R_mtx.npy')\n",
    "    Rt = np.load(savedir+'Rt.npy')\n",
    "    P_mtx = np.load(savedir+'P_mtx.npy')\n",
    "    inverse_newcam_mtx = np.load(savedir+'inverse_newcam_mtx.npy')\n",
    "    \n",
    "    return rotation_vector, translation_vector,R_mtx,Rt,P_mtx,inverse_newcam_mtx\n",
    "\n",
    "# Calculate the real Z coordinate based on the center of the image\n",
    "def calculate_z_total_points(world_points, X_center, Y_center):\n",
    "    \n",
    "    total_points_used = len(world_points)\n",
    "    \n",
    "    for i in range(1,total_points_used):\n",
    "    # start from 1, given for center Z=d*\n",
    "    # to center of camera\n",
    "        wX = world_points[i,0]-X_center\n",
    "        wY = world_points[i,1]-Y_center\n",
    "        wd = world_points[i,2]\n",
    "        print(wd)\n",
    "\n",
    "        d1 = np.sqrt(np.square(wX) + np.square(wY))\n",
    "        wZ = np.sqrt(np.square(wd) - np.square(d1))\n",
    "        world_points[i,2] = wZ\n",
    "\n",
    "    print(world_points)    \n",
    "    return world_points\n",
    "\n",
    "# Lets the check the accuracy here : \n",
    "# In this script we make sure that the difference and the error are acceptable in our project. \n",
    "# If not, maybe we need more calibration images and get more points or better points\n",
    "\n",
    "def calculate_accuracy(worldPoints,imagePoints):\n",
    "    s_arr=np.array([0], dtype = np.float32)\n",
    "    size_points=len(worldPoints)\n",
    "    s_describe=np.empty((size_points,),dtype = np.float32)\n",
    "    \n",
    "    rotation_vector, translation_vector,R_mtx,Rt,P_mtx,inverse_newcam_mtx = load_checking_parameters(savedir)\n",
    "\n",
    "    for i in range(0,size_points):\n",
    "        print(\"=======POINT # \" + str(i) +\" =========================\")\n",
    "    \n",
    "        print(\"Forward: From World Points, Find Image Pixel\\n\")\n",
    "        XYZ1 = np.array([[worldPoints[i,0],worldPoints[i,1],worldPoints[i,2],1]], dtype=np.float32)\n",
    "        XYZ1 = XYZ1.T\n",
    "        print(\"---- XYZ1\\n\")\n",
    "        print(XYZ1)\n",
    "        suv1 = P_mtx.dot(XYZ1)\n",
    "        print(\"---- suv1\\n\")\n",
    "        print(suv1)\n",
    "        s = suv1[2,0]    \n",
    "        uv1 = suv1/s\n",
    "        print(\"====>> uv1 - Image Points\\n\")\n",
    "        print(uv1)\n",
    "        print(\"=====>> s - Scaling Factor\\n\")\n",
    "        print(s)\n",
    "        s_arr = np.array([s/total_points_used + s_arr[0]], dtype = np.float32)\n",
    "        s_describe[i] = s\n",
    "        if writeValues == True: \n",
    "            np.save(savedir+'s_arr.npy', s_arr)\n",
    "\n",
    "        print(\"Solve: From Image Pixels, find World Points\")\n",
    "\n",
    "        uv_1 = np.array([[imagePoints[i,0],imagePoints[i,1],1]], dtype=np.float32)\n",
    "        uv_1 = uv_1.T\n",
    "        print(\"=====> uv1\\n\")\n",
    "        print(uv_1)\n",
    "        suv_1 = s * uv_1\n",
    "        print(\"---- suv1\\n\")\n",
    "        print(suv_1)\n",
    "\n",
    "        print(\"Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\\n\")\n",
    "        xyz_c = inverse_newcam_mtx.dot(suv_1)\n",
    "        xyz_c = xyz_c-translation_vector\n",
    "        print(\"---- xyz_c\\n\")\n",
    "        inverse_R_mtx = np.linalg.inv(R_mtx)\n",
    "        XYZ = inverse_R_mtx.dot(xyz_c)\n",
    "        print(\"---- XYZ\\n\")\n",
    "        print(XYZ)\n",
    "\n",
    "        if calculatefromCam == False:\n",
    "            cXYZ = cameraXYZ.calculate_XYZ(imagePoints[i,0],imagePoints[i,1])\n",
    "            print(\"camXYZ\")\n",
    "            print(cXYZ)\n",
    "\n",
    "\n",
    "    s_mean, s_std = np.mean(s_describe), np.std(s_describe)\n",
    "\n",
    "    print(\">>>>>>>>>>>>>>>>>>>>> S RESULTS\\n\")\n",
    "    print(\"Mean: \"+ str(s_mean))\n",
    "    #print(\"Average: \" + str(s_arr[0]))\n",
    "    print(\"Std: \" + str(s_std))\n",
    "\n",
    "    print(\">>>>>> S Error by Point\\n\")\n",
    "\n",
    "    for i in range(0,total_points_used):\n",
    "        print(\"Point \"+str(i))\n",
    "        print(\"S: \" + str(s_describe[i]) + \" Mean: \" + str(s_mean) + \" Error: \" + str(s_describe[i]-s_mean))\n",
    "        \n",
    "    return s_mean, s_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cx:324.1181529149326cy:232.74909600958745\n"
     ]
    }
   ],
   "source": [
    "# load center points from New Camera matrix\n",
    "cx, cy = get_image_center(savedir)\n",
    "print(\"cx:{0}\".format(cx) + \"cy:{0}\".format(cy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cx:324.1181529149326cy:232.74909600958745\n",
      "solvePNP\n",
      "Sucess: True\n",
      "Rotation Vector:\n",
      " [[ 2.07544283]\n",
      " [ 2.13371275]\n",
      " [-0.07512918]]\n",
      "Translation Vector:\n",
      " [[-0.27210446]\n",
      " [ 0.03013223]\n",
      " [12.50887356]]\n",
      "=======POINT # 0 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[ 0.25 ]\n",
      " [-0.125]\n",
      " [ 0.   ]\n",
      " [ 1.   ]]\n",
      "---- suv1\n",
      "\n",
      "[[3699.60249607]\n",
      " [3128.13201132]\n",
      " [  12.46114497]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[296.89105653]\n",
      " [251.03086583]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.46114497126875\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[324.11816]\n",
      " [232.7491 ]\n",
      " [  1.     ]]\n",
      "---- suv1\n",
      "\n",
      "[[4038.8835  ]\n",
      " [2900.3203  ]\n",
      " [  12.461145]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[-0.02834528]\n",
      " [ 0.2663943 ]\n",
      " [ 0.07387464]]\n",
      "=======POINT # 1 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "---- suv1\n",
      "\n",
      "[[3824.70380404]\n",
      " [2936.57580954]\n",
      " [  12.50887356]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[305.75925054]\n",
      " [234.75941267]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.508873557390654\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[299.]\n",
      " [239.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[3740.1533  ]\n",
      " [2989.6208  ]\n",
      " [  12.508874]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[ 0.06495211]\n",
      " [-0.09768737]\n",
      " [-0.01774169]]\n",
      "=======POINT # 2 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[ 1. ]\n",
      " [-1.5]\n",
      " [ 0. ]\n",
      " [ 1. ]]\n",
      "---- suv1\n",
      "\n",
      "[[2458.11508366]\n",
      " [3656.66188228]\n",
      " [  12.24005219]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[200.82553944]\n",
      " [298.74561201]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.24005218901118\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[198.]\n",
      " [301.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[2423.5303  ]\n",
      " [3684.2556  ]\n",
      " [  12.240052]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[ 1.03354951]\n",
      " [-1.53972124]\n",
      " [-0.00831494]]\n",
      "=======POINT # 3 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[1. ]\n",
      " [1.5]\n",
      " [0. ]\n",
      " [1. ]]\n",
      "---- suv1\n",
      "\n",
      "[[5056.66554913]\n",
      " [3795.07808545]\n",
      " [  12.47377326]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[405.38379554]\n",
      " [304.24459433]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.473773260686762\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[402.]\n",
      " [308.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[5014.4565  ]\n",
      " [3841.922   ]\n",
      " [  12.473773]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[ 1.05653644]\n",
      " [ 1.45205181]\n",
      " [-0.01251033]]\n",
      "=======POINT # 4 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[-1. ]\n",
      " [ 1.5]\n",
      " [ 0. ]\n",
      " [ 1. ]]\n",
      "---- suv1\n",
      "\n",
      "[[5191.29252442]\n",
      " [2216.4897368 ]\n",
      " [  12.77769493]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[406.27770146]\n",
      " [173.46553895]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.777694925770128\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[404.]\n",
      " [172.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[5162.1885  ]\n",
      " [2197.7634  ]\n",
      " [  12.777695]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[-1.02143504e+00]\n",
      " [ 1.46488684e+00]\n",
      " [ 5.29728718e-04]]\n",
      "=======POINT # 5 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[-1. ]\n",
      " [-1.5]\n",
      " [ 0. ]\n",
      " [ 1. ]]\n",
      "---- suv1\n",
      "\n",
      "[[2592.74205895]\n",
      " [2078.07353363]\n",
      " [  12.54397385]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[206.69224036]\n",
      " [165.66309511]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.543973854094546\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[202.]\n",
      " [168.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[2533.8828  ]\n",
      " [2107.3877  ]\n",
      " [  12.543974]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[-0.96379794]\n",
      " [-1.56831046]\n",
      " [-0.01098458]]\n",
      "=======POINT # 6 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[ 2. ]\n",
      " [-2.5]\n",
      " [ 0. ]\n",
      " [ 1. ]]\n",
      "---- suv1\n",
      "\n",
      "[[1524.61810752]\n",
      " [4399.81732222]\n",
      " [  12.01018433]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[126.94377249]\n",
      " [366.34053237]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.010184332577635\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[126.]\n",
      " [365.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[1513.2832  ]\n",
      " [4383.7173  ]\n",
      " [  12.010184]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[ 1.98122401e+00]\n",
      " [-2.51402937e+00]\n",
      " [ 1.78651413e-03]]\n",
      "=======POINT # 7 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[2. ]\n",
      " [2.5]\n",
      " [0. ]\n",
      " [1. ]]\n",
      "---- suv1\n",
      "\n",
      "[[5855.53554997]\n",
      " [4630.51099417]\n",
      " [  12.39971945]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[472.23129302]\n",
      " [373.43675493]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.399719452036942\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[468.]\n",
      " [378.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[5803.0684  ]\n",
      " [4687.0938  ]\n",
      " [  12.399719]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[ 2.06832775]\n",
      " [ 2.44033259]\n",
      " [-0.01525552]]\n",
      "=======POINT # 8 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[-2. ]\n",
      " [ 2.5]\n",
      " [ 0. ]\n",
      " [ 1. ]]\n",
      "---- suv1\n",
      "\n",
      "[[6124.78950056]\n",
      " [1473.33429686]\n",
      " [  13.00756278]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[470.86372775]\n",
      " [113.26751379]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "13.007562782203673\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[472.]\n",
      " [111.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[6139.5693  ]\n",
      " [1443.8395  ]\n",
      " [  13.007563]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[-2.0352983 ]\n",
      " [ 2.51626309]\n",
      " [ 0.00672997]]\n",
      "=======POINT # 9 =========================\n",
      "Forward: From World Points, Find Image Pixel\n",
      "\n",
      "---- XYZ1\n",
      "\n",
      "[[-2. ]\n",
      " [-2.5]\n",
      " [ 0. ]\n",
      " [ 1. ]]\n",
      "---- suv1\n",
      "\n",
      "[[1793.87205811]\n",
      " [1242.64062491]\n",
      " [  12.61802766]]\n",
      "====>> uv1 - Image Points\n",
      "\n",
      "[[142.16738987]\n",
      " [ 98.48136794]\n",
      " [  1.        ]]\n",
      "=====>> s - Scaling Factor\n",
      "\n",
      "12.618027662744366\n",
      "Solve: From Image Pixels, find World Points\n",
      "=====> uv1\n",
      "\n",
      "[[141.]\n",
      " [103.]\n",
      " [  1.]]\n",
      "---- suv1\n",
      "\n",
      "[[1779.1418  ]\n",
      " [1299.6569  ]\n",
      " [  12.618028]]\n",
      "Get camera coordinates, multiply by inverse Camera Matrix, subtract tvec1\n",
      "\n",
      "---- xyz_c\n",
      "\n",
      "---- XYZ\n",
      "\n",
      "[[-1.93211591]\n",
      " [-2.5150978 ]\n",
      " [-0.01166329]]\n",
      ">>>>>>>>>>>>>>>>>>>>> S RESULTS\n",
      "\n",
      "Mean: 12.504101\n",
      "Std: 0.25889283\n",
      ">>>>>> S Error by Point\n",
      "\n",
      "Point 0\n",
      "S: 12.461145 Mean: 12.504101 Error: -0.0429554\n",
      "Point 1\n",
      "S: 12.508874 Mean: 12.504101 Error: 0.00477314\n",
      "Point 2\n",
      "S: 12.240052 Mean: 12.504101 Error: -0.26404858\n",
      "Point 3\n",
      "S: 12.473773 Mean: 12.504101 Error: -0.030327797\n",
      "Point 4\n",
      "S: 12.777695 Mean: 12.504101 Error: 0.2735939\n",
      "Point 5\n",
      "S: 12.543974 Mean: 12.504101 Error: 0.039873123\n",
      "Mean:12.504100799560547Std:0.25889283418655396\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "# import camera_realworld_xyz\n",
    "\n",
    "writeValues = True\n",
    "calculatefromCam = True\n",
    "display = False\n",
    "savedir = \"camera_data/\"\n",
    "# cameraXYZ = camera_realworld_xyz.camera_realtimeXYZ()\n",
    "# test camera calibration against all points, calculating XYZ\n",
    "\n",
    "# load camera calibration\n",
    "cam_mtx,dist,roi,newcam_mtx,inverse_newcam_mtx = load_parameters(savedir, display) \n",
    "\n",
    "# load center points from New Camera matrix\n",
    "cx, cy = get_image_center(savedir)\n",
    "print(\"cx:{0}\".format(cx) + \"cy:{0}\".format(cy))\n",
    "\n",
    "# world center + 9 world points\n",
    "\n",
    "total_points_used = 6\n",
    "\n",
    "X_center = 0.25\n",
    "Y_center = -0.125\n",
    "# Z_center = -85.0\n",
    "Z_center = 0\n",
    "distance  = 0\n",
    "# world_points = np.array([[X_center,Y_center,Z_center],\n",
    "#                       [0.0, -22.0, -86.0], \n",
    "#                       [0.0, 0.0, -86.0],\n",
    "#                       [0.0, 22.0, -86.0],  \n",
    "#                       [15.0, -22.0, -86.0],\n",
    "#                       [15.0, 0.0, -86.0],\n",
    "#                       [15.0, 22.0, -86.0],\n",
    "#                       [-15.0, -22.0, -86.0],\n",
    "#                       [-15.0, 0.0, -86.0],\n",
    "#                       [-15.0, 22.0,-86.0]],dtype=np.float32)\n",
    "\n",
    "world_points = np.array([[X_center,Y_center,Z_center],\n",
    "                         [0.0, 0.0, Z_center],\n",
    "                         [1.0, -1.5, Z_center],\n",
    "                         [1.0, 1.5, Z_center],  \n",
    "                         [-1.0, 1.5,Z_center],\n",
    "                         [-1, -1.5, Z_center],\n",
    "                         [2.0, -2.5, Z_center],\n",
    "                         [2.0, 2.5, Z_center],  \n",
    "                         [-2.0, 2.5, Z_center],\n",
    "                         [-2, -2.5, Z_center],],dtype=np.float32)\n",
    "\n",
    "\n",
    "# MANUALLY INPUT THE DETECTED IMAGE COORDINATES HERE - Using function onclick \n",
    "\n",
    "# [u,v] center + 9 Image points\n",
    "#image_points=np.array([[cx,cy],\n",
    "#                       [189, 372],\n",
    "#                       [574,362],\n",
    "#                       [950,347],\n",
    "#                       [206,612],\n",
    "#                       [583,603],\n",
    "#                       [955,596],\n",
    "#                       [189,122],\n",
    "#                       [564,107],\n",
    "#                       [937,98]], dtype=np.float32)\n",
    "\n",
    "image_points = np.array([[cx,cy],\n",
    "                        [299,239],\n",
    "                        [198,301],\n",
    "                        [402,308],\n",
    "                        [404,172],\n",
    "                        [202,168],\n",
    "                        [126,365],\n",
    "                        [468,378],\n",
    "                        [472,111],\n",
    "                        [141,103]], dtype=np.float32)\n",
    "\n",
    "# For Real World Points, calculate Z from d*\n",
    "# world_points = calculate_z_total_points (world_points, X_center, Y_center)\n",
    "# print(world_points)\n",
    "\n",
    "\n",
    "# Get rotatio n and translation_vector from the parameters of the camera, given a set of 2D and 3D points\n",
    "print(\"solvePNP\")\n",
    "(success, rotation_vector, translation_vector) = cv2.solvePnP(world_points, image_points, newcam_mtx, dist, useExtrinsicGuess = False, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "if success:\n",
    "    print(\"Sucess:\", success)\n",
    "    print (\"Rotation Vector:\\n {0}\".format(rotation_vector))\n",
    "    print (\"Translation Vector:\\n {0}\".format(translation_vector))\n",
    "    \n",
    "    if writeValues: \n",
    "        save_parameters(savedir,rotation_vector, translation_vector,newcam_mtx)\n",
    "    \n",
    "\n",
    "# Check the accuracy now\n",
    "mean, std = calculate_accuracy(world_points, image_points)\n",
    "print(\"Mean:{0}\".format(mean) + \"Std:{0}\".format(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from the calibration_matrix.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file contains the camera matrix and de dist_coeff in a dictionary - list format\n",
    "with open(r'calibration_matrix.yaml') as file:\n",
    "    doc = yaml.full_load(file)\n",
    "    mtx = doc[\"camera_matrix\"]\n",
    "    dist = doc[\"dist_coeff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Example - 3D to 2D Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function from 3D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = True\n",
    "image_path = './final_pictures/img1610101287.71.png'\n",
    "# world_coordinate = (17.51,17.83,-84.253)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_3d_to_2d(image_path, world_coordinates, draw):\n",
    "     \n",
    "    im = cv2.imread(image_path);\n",
    "    size = im.shape\n",
    "    \n",
    "    # load camera calibration\n",
    "    savedir = \"camera_data/\"\n",
    "    dist = np.load(savedir+'dist.npy')\n",
    "    newcam_mtx = np.load(savedir+'newcam_mtx.npy')\n",
    "    rotation_vector = np.load(savedir+'rotation_vector.npy')\n",
    "    translation_vector = np.load(savedir+'translation_vector.npy')\n",
    "    \n",
    "    # Expected this format -> np.array([(0.0, 0.0, 30)])\n",
    "    world_coordinates = np.array([world_coordinates])\n",
    "    (new_point2D, jacobian) = cv2.projectPoints(world_coordinates, rotation_vector, translation_vector, newcam_mtx, dist)    \n",
    "    print(\"New_point2D:\", new_point2D)\n",
    "    \n",
    "    if draw :\n",
    "        cv2.circle(im, (int(new_point2D[0][0][0]),int(new_point2D[0][0][1])),5,(255,0,0), -1)\n",
    "        # Display image\n",
    "        cv2.imshow(\"Test\", im)\n",
    "        #cv2.imwrite(image_path, im)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()    \n",
    "    \n",
    "    return new_point2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New_point2D: [[[305.76307639 234.75780037]]]\n"
     ]
    }
   ],
   "source": [
    "world_coordinate = (0.0, 0.0, 0.0)\n",
    "\n",
    "new_point2D = from_3d_to_2d(image_path, world_coordinate, draw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New_point2D: [[[168.05476319 261.66387153]]]\n"
     ]
    }
   ],
   "source": [
    "# world_coordinate = (4.61, 38.44, -14.26)\n",
    "world_coordinate = (0.47, -2.0, 0.0) \n",
    "new_point2D = from_3d_to_2d(image_path, world_coordinate, draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function from to 2D to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working --> new solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_2d_to_3d(image_coordinates):\n",
    "     \n",
    "    # load camera calibration\n",
    "    savedir = \"camera_data/\"\n",
    "    cam_mtx,dist,roi,newcam_mtx,inverse_newcam_mtx = load_parameters(savedir, display)\n",
    "    R_mtx = np.load(savedir + 'R_mtx.npy')\n",
    "    inverse_R_mtx = np.linalg.inv(R_mtx)\n",
    "    s_arr = np.load(savedir + 's_arr.npy')\n",
    "    scalingfactor = s_arr[0]\n",
    "    # print(s_arr[0])\n",
    "    \n",
    "    # Expected this format -> np.array([(0.0, 0.0, 30)])\n",
    "    u,v = image_coordinates\n",
    "                                          \n",
    "    #Solve: From Image Pixels, find World Points\n",
    "    uv_1 = np.array([[u,v,1]], dtype = np.float32)\n",
    "    uv_1 = uv_1.T\n",
    "    suv_1 = scalingfactor * uv_1\n",
    "    xyz_c = inverse_newcam_mtx.dot(suv_1)\n",
    "    xyz_c = xyz_c - translation_vector\n",
    "    XYZ = inverse_R_mtx.dot(xyz_c)\n",
    "    \n",
    "    return XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_coordinates = [946.65573404,517.46556152]\n",
    "image_coordinates = [195, 302]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47543352]\n",
      " [-2.19959721]\n",
      " [-8.7027375 ]]\n"
     ]
    }
   ],
   "source": [
    "new_point3D = from_2d_to_3d(image_coordinates)\n",
    "print(new_point3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting coordinates from images - clicking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, params): \n",
    "      \n",
    "    # checking for left mouse clicks \n",
    "    if event == cv2.EVENT_LBUTTONDOWN: \n",
    "  \n",
    "        # displaying the coordinates on the Shell \n",
    "        print(x, ' ', y)\n",
    "        images_coordinates = image_coordinates.append([x,y])\n",
    "        # displaying the coordinates \n",
    "        # on the image window \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        cv2.putText(img, str(x) + ',' +\n",
    "                    str(y), (x,y), font, \n",
    "                    0.5, (255, 0, 0), 2) \n",
    "        cv2.imshow('image', img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195   302\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_path = './final_pictures/img1610101287.71.png'\n",
    "image_coordinates = []    \n",
    "# reading the image \n",
    "img = cv2.imread(image_path, 1) \n",
    "  \n",
    "# displaying the image \n",
    "cv2.imshow('image', img) \n",
    "  \n",
    "# setting mouse hadler for the image \n",
    "# and calling the click_event() function \n",
    "cv2.setMouseCallback('image', click_event)\n",
    "  \n",
    "# wait for a key to be pressed to exit \n",
    "cv2.waitKey(0) \n",
    "  \n",
    "# close the window \n",
    "cv2.destroyAllWindows() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOURCE**\n",
    "https://www.fdxlabs.com/calculate-x-y-z-real-world-coordinates-from-a-single-camera-using-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distancia de la lente al centro : 85 cm - 0.85 m\n",
    "\n",
    "Coordenadas x,y,z de los puntos:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting colors with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
